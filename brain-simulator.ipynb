{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/Jeremy/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa8fa641cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from Hang.utils_u_groupnorm_pytorchLightning import *\n",
    "from utils import *\n",
    "import time as time\n",
    "import nibabel as nib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(5)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"0001\",\"0017\",\"0018\",\"0038\",\"0040\",\"0042\",\"0046\",\"0087\",\"0090\",\"0108\",\"0116\",\"0131\",\"0178\",\"0190\",\n",
    "           \"0227\",\"0248\",\"0267\",\"0282\",\"0285\",\"0398\",\"0448\",\"0466\",\"0504\",\"0514\",\"0535\",\"0564\",\"0598\",\"0606\",\n",
    "           \"0607\",\"0618\",\"0620\",\"0623\",\"0642\",\"0646\",\"0655\",\"0668\",\"0675\",\"0681\",\"0719\",\"0761\",\"0762\",\"0783\",\n",
    "           \"0786\",\"0868\",\"0877\",\"0887\",\"0895\",\"0902\",\"0931\",\"0979\",\"1007\",\"1013\",\"1029\",\"1033\",\"1068\",\"1142\",\n",
    "           \"1143\",\"1163\",\"1190\",\"1260\",\"1275\",\"1347\",\"1383\",\"1389\",\"1416\",\"1435\",\"1441\",\"1447\",\"1451\",\"1514\",\n",
    "           \"1520\",\"1602\",\"1611\",\"1621\",\"1680\",\"1684\",\"1686\",\"1710\",\"1720\",\"1739\",\"1743\",\"1749\",\"1753\",\"1760\",\n",
    "           \"1795\",\"1805\",\"1845\",\"1858\",\"1876\",\"1889\",\"1892\",\"1898\",\"1899\",\"1918\",\"1924\",\"1932\",\"1952\",\"1961\",\n",
    "           \"1972\",\"1987\",\"2003\",\"2007\",\"2016\",\"2020\",\"2022\",\"2030\",\"2045\",\"2047\",\"2049\",\"2053\",\"2055\",\"2074\",\n",
    "           \"2077\",\"2080\",\"2091\",\"2094\",\"2103\",\"2115\",\"2128\",\"2142\",\"2144\",\"2146\",\"2152\",\"2156\",\"2158\",\"2160\",\n",
    "           \"2161\",\"2179\",\"2180\",\"2181\",\"2183\",\"2186\",\"2188\",\"2212\",\"2221\",\"2231\",\"2234\",\"2245\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [numbers[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_subjects = [\"0017\", \"0018\", \"0038\", \"0040\", \"0042\", \"0046\", \"0087\"]\n",
    "roi_files = []\n",
    "roi_fastt2_files = []\n",
    "for subject in roi_subjects:\n",
    "    roi_files.append(f\"../{subject}/roi.nii.gz\")\n",
    "    roi_fastt2_files.append(f\"../{subject}/FASTT2_FULL.nii.gz\")\n",
    "rois = []\n",
    "fastt2 = [[] for i in range(6)]\n",
    "for file in roi_files:\n",
    "    rois.append(nib.load(file).get_fdata())\n",
    "for idx in range(len(roi_fastt2_files)):\n",
    "    brain = nib.load(roi_fastt2_files[idx]).get_fdata()\n",
    "    for i in range(6):\n",
    "        te = brain[:,:,:,i]\n",
    "        fastt2[i] += te[rois[idx] == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.array(rois)\n",
    "fastt2 = np.array(fastt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.704228281640453\n"
     ]
    }
   ],
   "source": [
    "NOISE_SCALE = fastt2[0].mean()/SNR\n",
    "print(NOISE_SCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab 256x256 brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBrains(brainRef, labels, masks, noise):\n",
    "    label = labels[0].copy()\n",
    "    brains = np.zeros((NUM_BRAINS,6)+label[0].shape)\n",
    "#     echoTimes = [10 * i for i in range(33)]\n",
    "#     echoTimes = [0, 7.5, 17.5, 67.5, 147.5, 307.5]\n",
    "    echoTimes = [10, 20, 40, 80, 160, 320]\n",
    "    for labelIdx in range(len(labels)):\n",
    "        label = labels[labelIdx].copy()\n",
    "        for i in range(len(echoTimes)):\n",
    "            brains[labelIdx,i] = label[0] * np.exp(-echoTimes[i] / (label[3] + 1e-16)) + \\\n",
    "                                 label[1] * np.exp(-echoTimes[i] / (label[4] + 1e-16)) + \\\n",
    "                                 label[2] * np.exp(-echoTimes[i] / (label[5] + 1e-16))\n",
    "            np.nan_to_num(brains[labelIdx,i], copy=False)\n",
    "        scale = brainRef[labelIdx,0] / (brains[labelIdx,0] + 1e-16)\n",
    "        for i in range(len(echoTimes)):\n",
    "            brains[labelIdx,i] *= scale\n",
    "    brains += noise\n",
    "    for i in range(len(echoTimes)):\n",
    "        brains[:,i] *= masks\n",
    "#     brains = brains[:,1:]\n",
    "    print(brains.shape)\n",
    "    return brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 256, 256, 32)\n"
     ]
    }
   ],
   "source": [
    "batch = 1\n",
    "for q in range(0, len(numbers), batch):\n",
    "    fastt2_files, mask_files = [], []\n",
    "    w1_files, w2_files, w3_files = [], [], []\n",
    "    t1_files, t2_files, t3_files = [], [], []\n",
    "\n",
    "    for number in numbers[q:q+batch]:\n",
    "        file_root = \"../\" + number + \"/\"\n",
    "        mask_files.append(file_root + \"tightmask.nii.gz\")\n",
    "        fastt2_files.append(file_root + \"FASTT2_FULL.nii.gz\")\n",
    "        w1_files.append(file_root + \"w1.nii.gz\")\n",
    "        w2_files.append(file_root + \"w2.nii.gz\")\n",
    "        w3_files.append(file_root + \"w3.nii.gz\")\n",
    "        t1_files.append(file_root + \"t1.nii.gz\")\n",
    "        t2_files.append(file_root + \"t2.nii.gz\")\n",
    "        t3_files.append(file_root + \"t3.nii.gz\")\n",
    "\n",
    "    mask_array = []\n",
    "    brains = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(mask_files)):\n",
    "        mask_array.append(nib.load(mask_files[i]).get_fdata())\n",
    "\n",
    "    for i in range(len(mask_files)):\n",
    "        brain = nib.load(fastt2_files[i]).get_fdata().transpose((3,0,1,2)) * mask_array[i]\n",
    "        brains.append(brain)\n",
    "\n",
    "    for i in range(len(mask_files)):\n",
    "        label = []\n",
    "        label.append(nib.load(w1_files[i]).get_fdata() * mask_array[i])\n",
    "        label.append(nib.load(w2_files[i]).get_fdata() * mask_array[i])\n",
    "        label.append(nib.load(w3_files[i]).get_fdata() * mask_array[i])\n",
    "        label.append(nib.load(t1_files[i]).get_fdata() * mask_array[i])\n",
    "        label.append(nib.load(t2_files[i]).get_fdata() * mask_array[i])\n",
    "        label.append(nib.load(t3_files[i]).get_fdata() * mask_array[i])\n",
    "        labels.append(label)\n",
    "\n",
    "    # BIG NUMBER: n, 6, 256, 256, 32\n",
    "    brains = np.array(brains)\n",
    "    labels = np.array(labels)\n",
    "    mask_array = np.array(mask_array)\n",
    "\n",
    "    NUM_BRAINS = len(numbers[q:q+batch])\n",
    "    noise = np.random.normal(size=(NUM_BRAINS,6) + labels[0,0].shape, scale=NOISE_SCALE)\n",
    "    simbrains_200 = generateBrains(brains, labels, mask_array, noise)\n",
    "    for i in range(len(simbrains_200)):\n",
    "        newbrain = simbrains_200[i]\n",
    "        number = numbers[q:q+batch][i]\n",
    "        save_nii(newbrain.transpose((1,2,3,0)), f\"../{number}/FASTT2_SNR_200_SIM_NEW_TE.nii.gz\", f\"../{number}/w1.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
